{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vishu254-bit/vish/blob/main/Welcome_To_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
        "\n",
        "# --- Data Loading (Placeholder) ---\n",
        "# NOTE: Replace this with your actual data loading code.\n",
        "# You will need to load the NSL-KDD dataset from your local files.\n",
        "# Example: df = pd.read_csv('your_nsl_kdd_dataset.csv')\n",
        "# For demonstration, we will create a simple mock dataset.\n",
        "print(\"Loading dataset...\")\n",
        "X = np.random.rand(1000, 10) * 100 # 1000 samples, 10 features\n",
        "y = np.random.randint(0, 2, 1000)   # Binary labels (0 or 1)\n",
        "print(\"Dataset loaded successfully.\")\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# --- Define Models and Scaling Pipelines ---\n",
        "\n",
        "def evaluate_model(model, X_train, y_train, X_test, y_test, scaler=None):\n",
        "    \"\"\"\n",
        "    Trains and evaluates a model with an optional scaler.\n",
        "    \"\"\"\n",
        "    if scaler:\n",
        "        # Fit scaler on training data and transform both train and test data\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "\n",
        "        # Make predictions\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "    else:\n",
        "        # Train the model with no scaling\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate performance metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# --- Run Experiments ---\n",
        "svm_model = SVC(kernel='rbf', gamma='auto', random_state=42)\n",
        "\n",
        "# 1. No Scaling (Baseline)\n",
        "print(\"\\n--- Evaluating SVM with No Scaling (Baseline) ---\")\n",
        "accuracy_no_scale, precision_no_scale, recall_no_scale, f1_no_scale = evaluate_model(\n",
        "    svm_model, X_train, y_train, X_test, y_test\n",
        ")\n",
        "print(f\"Accuracy: {accuracy_no_scale:.4f}\")\n",
        "print(f\"Precision: {precision_no_scale:.4f}\")\n",
        "print(f\"F1-Score: {f1_no_scale:.4f}\")\n",
        "\n",
        "# 2. Min-Max Normalization\n",
        "print(\"\\n--- Evaluating SVM with Min-Max Normalization ---\")\n",
        "minmax_scaler = MinMaxScaler()\n",
        "accuracy_minmax, precision_minmax, recall_minmax, f1_minmax = evaluate_model(\n",
        "    svm_model, X_train, y_train, X_test, y_test, scaler=minmax_scaler\n",
        ")\n",
        "print(f\"Accuracy: {accuracy_minmax:.4f}\")\n",
        "print(f\"Precision: {precision_minmax:.4f}\")\n",
        "print(f\"F1-Score: {f1_minmax:.4f}\")\n",
        "\n",
        "# 3. Z-score Standardization\n",
        "print(\"\\n--- Evaluating SVM with Z-score Standardization ---\")\n",
        "zscore_scaler = StandardScaler()\n",
        "accuracy_zscore, precision_zscore, recall_zscore, f1_zscore = evaluate_model(\n",
        "    svm_model, X_train, y_train, X_test, y_test, scaler=zscore_scaler\n",
        ")\n",
        "print(f\"Accuracy: {accuracy_zscore:.4f}\")\n",
        "print(f\"Precision: {precision_zscore:.4f}\")\n",
        "print(f\"F1-Score: {f1_zscore:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uvBciYXVQyC",
        "outputId": "1b29cabe-d472-4d93-caa5-32da96b6d6c0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "Dataset loaded successfully.\n",
            "\n",
            "--- Evaluating SVM with No Scaling (Baseline) ---\n",
            "Accuracy: 0.5300\n",
            "Precision: 0.2809\n",
            "F1-Score: 0.3672\n",
            "\n",
            "--- Evaluating SVM with Min-Max Normalization ---\n",
            "Accuracy: 0.5033\n",
            "Precision: 0.4991\n",
            "F1-Score: 0.4987\n",
            "\n",
            "--- Evaluating SVM with Z-score Standardization ---\n",
            "Accuracy: 0.5133\n",
            "Precision: 0.5099\n",
            "F1-Score: 0.5098\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}